# CMU_LTI_Summer_Internship

## What motivated me to apply to this program?

**Research Interests**

As an undergraduate student studying artificial intelligence and cognitive science, I am broadly interested in understanding the underlying mechanisms of human social cognition and developing socially intelligent systems that can interact with humans safely. I believe language serves as a cornerstone for human thought, reasoning, and social interaction. Inspired by recent advancements in generative agents and social simulation, my specific research interests include but are not limited to:

1. Designing experiments and benchmarks to evaluate social intelligence in generative-agent-based environments, drawing insights from social psychology.
2. Leveraging generative-agent-based environments as social simulators to study social dynamics, particularly the emergence and evolution of social norms and institutions.
3. Evaluating large language models (LLMs) through the lens of cognitive science and designing more human-like language models.
4. AI ethics, fairness, and the application of AI for social good.

**Goals for This Program**

I am eager to join this program to collaborate with leading researchers in language technology. In particular, I am inspired by Prof. **Maarten Sap**’s work on assessing AI agent safety within complex social interactions and interactively training LLMs to enhance their social intelligence. Additionally, I greatly admire Prof. **Yonatan Bisk**’s research on improving LLMs’ theory-of-mind reasoning and incorporating inductive biases into language models. Furthermore, Prof. **Louis-Philippe Morency**’s research on artificial social intelligence strongly aligns with my passion for building socially aware AI systems by integrating and analyzing multimodal information.

With my background at the intersection of AI, cognitive science, and social science, I believe I can make meaningful contributions to this program and the CMU LTI community.

## What programming experience do I have?

**Programming Language and Tools**

Python / C / C++ / PyTorch / LaTeX / object-oriented programming (Advanced), jsPsych / JavaScript / Shell / Docker / Blender (intermediate)

**Projects I’ve worked on that require strong programming skills**

Project 1: Computational Modeling of Human Visual Pretense (in collaboration with Dr. Peng Qian and Prof. Tomer Ullman)

This project investigates visual pretense—a mode of imagination in which people use physical objects to stand for ideas in their minds, such as pointing to a bottle and saying “Suppose this is my car…”. I developed a computational model of the cognitive process underlying this behavior. The model integrates two modules, (1) a shape representation module that maps a visual or linguistic depiction (such as an image or a phrase) of real and pretend objects to a 3D point cloud, and (2) an analogical reasoning module that searches for a good alignment between the two point clouds of a real object and a pretend object. I tested this model’s predictions on the stimuli developed in previous human behavioral studies and compared model performance with that of other multimodal generative models.

Project 2: Fine-tuning LLaMA-7B using RLCD (in collaboration with Sonia Murthy, Dr. Jennifer Hu, and Prof. Tomer Ullman)

The goal of this project was to explore whether post-training alignment methods, such as RLHF, RLAIF, and RLCD, influence the internal diversity of large language models. To achieve this, I fine-tuned LLaMA-7B using reinforcement learning from contrastive distillation (RLCD) and evaluated its conceptual diversity through a word-color association task and a conceptual similarity judgment task. This work was later accepted for NAACL 2025. Although I was not listed as an author, I gained expertise in training large language models on FASRC GPUs, leveraging the Accelerate library for distributed training, and resolving multi-node communication challenges.

Project 3: Computational Modeling of Nonverbal Communication (conducted during my internship at Beijing Institute for General Artificial Intelligence)

To explore how nonverbal signals, such as pointing and gazing, influence agents’ cognition and action planning in social interactions, I developed Heider-Simmel-style animations using a physics engine (i.e., pybox2d). The agents could communicate through pointing and perform hierarchical planning within a decentralized POMDP framework. The animations aligned with human intuition, demonstrating how pointing can assist or obstruct others while minimizing movement costs. These findings shed light on how nonverbal signals contribute to joint attention and shape cognitive processes in social interactions.

## What experience do I have with natural language processing, machine learning, linguistics, or other non-CS academic areas relevant to my interest in language technologies?

## Are there unique elements of my background that could help me contribute to building more inclusive language technologies in the future?

## Do I have any academic or leadership achievements that I would like to tell you about?

1. Ranked 1st out of 570,000+ in the Chinese College Entrance Examination (Hunan Province), earning admission to Peking University's highly selective Tong Class. This program, representing the highest academic tier at Peking University, admits only the most elite students based on both college entrance examination results and first-year university performance.
2. Awarded multiple prestigious scholarships, including:
- Mingde Scholarship (Top 50 among all freshmen)
- XueErSi Boya Scholarship (Top 25 out of 4,000+ students)
- Social Work Excellence Award
3. Served as Monitor of the PKU Tong Class, organizing class activities and fostering community engagement. Additionally, co-led the Tongzhi Talk Series, which invites outstanding peers to give talks on AI, computer science, and cognitive science.
4. Worked as a Teaching Assistant for the course Mathematical Foundations for AI in Spring 2024.
5. Served as a Reviewer for the Cognitive Science Society in 2024 and 2025.
6. Invited to give a talk at IJTCS-FAW 2023 Conscious Turing Machine (CTM) workshop.


